{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "__author__ = 'xie'\n",
    "\n",
    "#updated with some commen, 14/07/2015\n",
    "#This script is created to set up a cross validation scheme to allow train/test split within the training dataset provided. \n",
    "#This allow us to benchmark our algorithm with labelled data \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "def xgb_benchmark_data():\n",
    "    #data handling, take the input data, and merge them accordingly\n",
    "    #this is the original data handling routine of the xgb benchark script shared by Gilberto Titericz Junior\n",
    "    train = pd.read_csv('./input/train_set.csv', parse_dates=[2,])\n",
    "    test = pd.read_csv('./input/test_set.csv', parse_dates=[3,])\n",
    "    tube_data = pd.read_csv('../input/tube.csv')\n",
    "    bill_of_materials_data = pd.read_csv('./input/bill_of_materials.csv')\n",
    "    specs_data = pd.read_csv('./input/specs.csv')\n",
    "\n",
    "\n",
    "\n",
    "    train = pd.merge(train, tube_data, on ='tube_assembly_id')\n",
    "    train = pd.merge(train, bill_of_materials_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, tube_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, bill_of_materials_data, on ='tube_assembly_id')\n",
    "\n",
    "\n",
    "\n",
    "    # create some new features\n",
    "    train['year'] = train.quote_date.dt.year\n",
    "    train['month'] = train.quote_date.dt.month\n",
    "    #train['dayofyear'] = train.quote_date.dt.dayofyear\n",
    "    #train['dayofweek'] = train.quote_date.dt.dayofweek\n",
    "    #train['day'] = train.quote_date.dt.day\n",
    "\n",
    "    test['year'] = test.quote_date.dt.year\n",
    "    test['month'] = test.quote_date.dt.month\n",
    "    #test['dayofyear'] = test.quote_date.dt.dayofyear\n",
    "    #test['dayofweek'] = test.quote_date.dt.dayofweek\n",
    "    #test['day'] = test.quote_date.dt.day\n",
    "\n",
    "    # drop useless columns and create labels\n",
    "    idx = test.id.values.astype(int)\n",
    "    test = test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1)\n",
    "    labels = train.cost.values\n",
    "\n",
    "    #'tube_assembly_id', 'supplier', 'bracket_pricing', 'material_id', 'end_a_1x', 'end_a_2x', 'end_x_1x', 'end_x_2x',\n",
    "    #  'end_a', 'end_x'\n",
    "    #for some reason material_id cannot be converted to categorical variable\n",
    "    train = train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis = 1)\n",
    "\n",
    "    train['material_id'].replace(np.nan,' ', regex=True, inplace= True)\n",
    "    test['material_id'].replace(np.nan,' ', regex=True, inplace= True)\n",
    "    for i in range(1,9):\n",
    "        column_label = 'component_id_'+str(i)\n",
    "        # print(column_label)\n",
    "        train[column_label].replace(np.nan,' ', regex=True, inplace= True)\n",
    "        test[column_label].replace(np.nan,' ', regex=True, inplace= True)\n",
    "\n",
    "    train.fillna(0, inplace = True)\n",
    "    test.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "    # convert data to numpy array\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    # label encode the categorical variables\n",
    "    for i in range(train.shape[1]):\n",
    "        if i in [0,3,5,11,12,13,14,15,16,20,22,24,26,28,30,32,34]:\n",
    "            print(i,list(train[1:5,i]) + list(test[1:5,i]))\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[:,i]) + list(test[:,i]))\n",
    "            train[:,i] = lbl.transform(train[:,i])\n",
    "            test[:,i] = lbl.transform(test[:,i])\n",
    "\n",
    "    return train, test, idx, labels\n",
    "\n",
    "\n",
    "# pickle data routine in case you saved the data in a local environment\n",
    "def load_data(pickle_file):\n",
    "    load_file=open(pickle_file,'rb')\n",
    "    data=cPickle.load(load_file)\n",
    "    return  data\n",
    "\n",
    "# xgb learner, inline with the xgb benchmark script shared by Gilberto Titericz Junior\n",
    "def xgb_learning(labels, train, test):\n",
    "    label_log = np.log1p(labels)\n",
    "    # fit a random forest model\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"eta\"] = 0.1\n",
    "    params[\"min_child_weight\"] = 6\n",
    "    params[\"subsample\"] = 0.87\n",
    "    params[\"colsample_bytree\"] = 0.50\n",
    "    params[\"scale_pos_weight\"] = 1.0\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 7\n",
    "    params[\"seed\"]=3\n",
    "\n",
    "    plst = list(params.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train, label=label_log)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "\n",
    "    num_rounds = 120\n",
    "    # model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    # preds = model.predict(xgtest)\n",
    "\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    preds1 = model.predict(xgtest)\n",
    "    preds = np.expm1(preds1)\n",
    "\n",
    "    # I have commented out the follownig line for fast run time \n",
    "    # preds = model.predict(xgtest)\n",
    "    # n=1\n",
    "    # for loop in range(n):\n",
    "    #     model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    #     preds1 = preds1 + model.predict(xgtest)\n",
    "    # preds = np.expm1( preds1/(n+1))\n",
    "    return  preds\n",
    "\n",
    "# sklearn LinearRegression\n",
    "def linear_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    linear=LinearRegression()\n",
    "    model=linear.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds\n",
    "\n",
    "# sklearn svm regression \n",
    "def svm_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
    "        kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    model=clf.fit(train, label_log)\n",
    "\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds\n",
    "# sklearn random forest regression\n",
    "def random_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=RandomForestRegressor(n_estimators=50, n_jobs=3)\n",
    "    model=clf.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    test_run=True\n",
    "    train, test, idx, labels=xgb_benchmark_data()\n",
    "\n",
    "    # if test run, then perform the cross validation\n",
    "    if test_run:\n",
    "        print(\"perform cross validation\")\n",
    "        rmse=[]\n",
    "        rnd_state=np.random.RandomState(1234)\n",
    "        for run in range(1, 11):\n",
    "            train_i, test_i = train_test_split(np.arange(train.shape[0]), train_size = 0.8, random_state = rnd_state )\n",
    "            tr_train=train[train_i]\n",
    "            tr_test=train[test_i]\n",
    "            tr_train_y=labels[train_i]\n",
    "            tr_test_y=labels[test_i]\n",
    "\n",
    "            # you can switch on/off each learninger as you wish by comment/uncomment\n",
    "            tr_preds=xgb_learning(tr_train_y, tr_train, tr_test)\n",
    "            #tr_preds=linear_learning(tr_train_y, tr_train, tr_test)\n",
    "            # tr_preds=svm_learning(tr_train_y, tr_train, tr_test)\n",
    "            #tr_preds=random_learning(tr_train_y, tr_train, tr_test)\n",
    "\n",
    "            rmse_score = (np.sum((np.log1p(tr_preds)-np.log1p(tr_test_y))**2)/len(test_i))**0.5\n",
    "            \n",
    "            #output test score with both real value and predicted price, this allow you to have a visual understand\n",
    "            #how close/far they are from each other\n",
    "            \n",
    "            compare=pd.DataFrame({\"tr_test_id\":test_i, \"cost_real\":tr_test_y, \"cost_pred\":tr_preds})\n",
    "            header=[\"tr_test_id\", \"cost_real\", \"cost_pred\"]\n",
    "            compare.to_csv('compare.csv', columns=header, index=False)\n",
    "            rmse.append(rmse_score)\n",
    "            print (\"logistic regression score for test run %i is %.6f\" %(run, rmse_score))\n",
    "        print (\"Mean logistic regression RMSE is %.6f:\" %np.mean(rmse))\n",
    "    else:\n",
    "        preds=xgb_learning(labels, train, test)\n",
    "        preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
    "        preds.to_csv('xgb_test.csv', index=False)\n",
    "\n",
    "    end_time=time.time()\n",
    "    duration=end_time-start_time\n",
    "    print (\"it takes %.3f seconds\"  %(duration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
